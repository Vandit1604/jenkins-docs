{"componentChunkName":"component---src-templates-article-js","path":"/2016/2016-08-17-jenkins-world-speaker-blog-aquilent/","result":{"data":{"asciidoc":{"html":"<div class=\"ulist\">\n<ul>\n<li>\n<p>jenkinsworld</p>\n</li>\n<li>\n<p>jenkinsworld2016\nauthor: hinman\n---</p>\n</li>\n</ul>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nThis is a guest post by Jenkins World speaker Neil Hunt, Senior DevOps Architect at <a href=\"https://www.aquilent.com/\">Aquilent</a>.\n</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>In smaller companies with a handful of apps and fewer silos, implementing CD\npipelines to support these apps is fairly straightforward using one of the many\ndelivery orchestration tools available today. There is likely a constrained\ntool set to support - not an abundance of flavors of applications and security\npractices - and generally fewer cooks in the kitchen. But in a larger\norganization, I have found that in the past, there were seemingly endless\nunique requirements and mountains to climb to reach this level of automation on\neach new project.</p>\n</div>\n<div class=\"admonitionblock caution\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Caution</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Neil will be <a href=\"https://www.cloudbees.com/lightning-talks\">presenting</a> more\nof this concept at <a href=\"https://www.cloudbees.com/jenkinsworld/home\">Jenkins World</a> in\nSeptember, register with the code <code>JWFOSS</code> for a 20% discount off your pass.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>Enter the Jenkins Pipeline plugin. My recently departed former company, a large\nfinancial services organization with a 600+ person IT organization and 150+\napplication portfolio, set out to implement continuous delivery\nenterprise-wide. After considering several pipeline orchestration tools, we\ndetermined the Pipeline plugin (at the time called Workflow) to be the superior\nsolution for our company. Pipeline has continued Jenkins' legacy of presenting\nan extensible platform with just the right set of features to allow\norganizations to scale its capabilities as they see fit, and do so rapidly. As\nearly adopters of Pipeline with a protracted set of requirements, we used it\nboth to accelerate the pace of onboarding new projects and to reduce the\nongoing feature delivery time of our applications.</p>\n</div>\n<div class=\"paragraph\">\n<p>In my presentation at Jenkins World, I will demonstrate the methods we used to\nenable this. A few examples:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>We leveraged the Pipeline Remote File Loader plugin to write shared common\ncode and sought and received community enhancements to these functions.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/jw-speaker-blog-aquient/jw-speaker-blog-aquilent-1-1.png\" alt=\"jw speaker blog aquilent 1 1\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p><em>Jenkinsfile, loading a shared AWS utilities function library</em></p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/jw-speaker-blog-aquient/jw-speaker-blog-aquilent-2.png\" alt=\"jw speaker blog aquilent 2\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p><em>awsUtils.groovy, snippets of some AWS functions</em></p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>We migrated from EC2 agents to Docker-based agents running on Amazon&#8217;s\nElastic Container Service, allowing us to spin up new executors in seconds\nand for teams to own their own executor definitions.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/jw-speaker-blog-aquient/jw-speaker-blog-aquilent-3.png\" alt=\"jw speaker blog aquilent 3\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Pipeline run #1 using standard EC2 executors, spinning up EC2 instance for each\nnode; Pipeline run #2 using shared ECS cluster with near-instant instantiation\nof a Docker agent in the cluster for each node.</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>We also created a Pipeline Library of common pipelines, enabling projects\nthat fit certain models to use ready-made end-to-end pipelines. Some\nexamples:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Maven JAR Pipeline: Pipeline that clones git repository, builds JAR file\nfrom pom.xml, deploys to Artifactory, and runs maven release plugin to\nincrement next version</p>\n</li>\n<li>\n<p>Angular.JS Pipeline: Pipeline that executes a grunt and bower build, then\nruns S3 sync to Amazon S3 bucket in Dev, then Stage, then Prod buckets.</p>\n</li>\n<li>\n<p>Pentaho Reports Pipeline: Pipeline that clones git repository, constructs\nzip file, and executes Pentaho Business Intelligence Platform CLI to import new\nset of reports in Dev, Stage, then Prod servers.</p>\n</li>\n</ul>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>Perhaps most critically, a shout-out to the saving grace of this quest for our\nsecurity and ops teams: the manual 'input' step! While the ambition of\ncontinuous delivery is to have as few of these as possible, this was the\nsingle-most pivotal feature in convincing others of Pipeline&#8217;s viability, since\nnow any step of the delivery process could be gate-checked by an LDAP-enabled\npermission group. Were it not for the availability of this step, we may still\nbe living in the world of: \"This seems like a great tool for development, but\nwe will have a segregated process for production deployments.\" Instead, we had\na pipeline full of many 'input' steps at first, and then used the data we\ncollected around the longest delays to bring management focus to them and unite\neveryone around the goal of strategically removing them, one by one.</p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image center\"><img src=\"/images/post-images/jw-speaker-blog-aquient/jw-speaker-blog-aquilent-4.png\" alt=\"jw speaker blog aquilent 4\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p><span class=\"image right\"><img src=\"/images/conferences/Jenkins-World_125x125.png\" alt=\"Jenkins World 125x125\"></span></p>\n</div>\n<div class=\"paragraph\">\n<p>Going forward, having recently joined Aquilent&#8217;s Cloud Solutions Architecture\nteam, I&#8217;ll be working with our project teams here to further mature the use of\nthese Pipeline plugin features as we move towards continuous delivery. Already,\nwe have migrated several components of our healthcare.gov project to Pipeline.\nThe team has been able to consolidate several Jenkins jobs into a single,\nvisible delivery pipeline, to maintain the lifecycle of the pipeline with our\napplication code base in our SCM, and to more easily integrate with our\nexternal tools.</p>\n</div>\n<div class=\"paragraph\">\n<p>Due to functional shortcomings in the early adoption stages of the Pipeline\nplugin and the ever-present political challenges of shifting organizational\npolicy, this has been and continues to be far from a bruise-free journey. But\nwe plodded through many of these issues to bring this to fruition and\nultimately reduced the number of manual steps in some pipelines from 12 down to\n1 and brought our 20+ Jenkins-minute pipelines to only six minutes after months\nof iteration. I hope you&#8217;ll join this session at Jenkins World and learn about\nour challenges and successes in achieving the promise of continuous delivery at\nenterprise scale.</p>\n</div>","document":{"title":"Continuously Delivering Continuous Delivery Pipelines","main":"Continuously Delivering Continuous Delivery Pipelines"},"author":{"fullName":"tags:"}}},"pageContext":{"id":"23113df6-ae24-5fc2-a4a3-9bc77851d866"}},"staticQueryHashes":[],"slicesMap":{}}